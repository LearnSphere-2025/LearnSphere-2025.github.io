---
layout: single
title: "🌱 BERT 이전의 자연어처리 & NLP 파이프라인"
---

# Kernel Academy AI Bootcamp (2025.07.25)

이번 포스트는 자연어 처리(NLP)의 흐름을 이해하고, BERT 이전의 주요 모델들과 핵심 개념들을 정리한 내용입니다. 또한, Hugging Face 기반의 NLP 분류 프로젝트 (낚시성 기사 분류)를 실습하며 전체 Pipeline을 구현해보았습니다.

---

## 📌 목차

1. BERT 이전의 주요 NLP 모델 흐름
2. 자연어처리 Task 이해 및 Hugging Face Pipeline
3. NLP 모델 학습 및 추론 실습 (낚시성 기사 분류)
4. 전체 파이프라인 요약

---

## 1. BERT 이전의 자연어 처리 모델 흐름

### 🔁 Seq2Seq (Sequence-to-Sequence)

- 입력 시퀀스를 고정된 벡터로 인코딩한 후 새로운 시퀀스를 생성  
- 응용 분야: **기계 번역**, **질문 생성**, **챗봇**
- 한계: 긴 문장일수록 정보 손실 → **장기 의존성 문제**

### 🔄 RNN과 개선형 구조 (LSTM, GRU)

- 시간 순서를 따라 정보를 전달
- **LSTM**: 게이트 구조로 장기 의존성 완화  
- **GRU**: LSTM보다 간단하지만 유사한 성능

### 🎯 Attention Mechanism

- Encoder의 마지막 벡터 의존 문제 해결
- 디코더가 입력 시퀀스 전체를 참조 → **가중치 기반 정보 선택**
- 장점: 문맥에 맞는 유연한 생성 가능

### ⚡ Transformer (2017)

- "Attention is All You Need"
- **완전한 Attention 기반 모델**
- 병렬 연산 가능 → 대규모 학습에 적합  
- 핵심 구성: Self-Attention, Multi-Head Attention, Positional Encoding, FFN, Residual Connection
- Encoder-Decoder 구조는 유지하지만, 내부적으로 RNN 없이 Attention만 사용

---

## 2. 📘 자연어처리 Task 이해하기

### 🏛 Hugging Face와 pipeline 모듈

```python
# 간단한 감성 분석 예시
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
print(classifier("I love this movie!"))
# 출력: [{'label': 'POSITIVE', 'score': 0.999...}]

**pipeline은 모델 로딩, 토크나이징, 추론, 후처리를 자동화하여 간편한 테스트 가능해줌

| Task                               | 설명             |
| ---------------------------------- | -------------- |
| **기계 번역 (Translation)**            | 언어 A → 언어 B    |
| **질문 응답 (QA)**                     | 질문에 대한 정답 추출   |
| **정보 추출 (Information Extraction)** | 문장에서 엔티티 추출    |
| **감성 분류 (Sentiment Analysis)**     | 텍스트의 감정 파악     |
| **요약 (Summarization)**             | 긴 문서의 핵심 내용 압축 |

| 지표            | 설명                         |
| ------------- | -------------------------- |
| **Precision** | 정답 판정 중 실제 정답 비율           |
| **Recall**    | 실제 정답 중 맞춘 비율              |
| **F1 Score**  | Precision + Recall 조화 평균   |
| **BLEU**      | 생성 텍스트의 유사도 측정 (n-gram 기반) |

“어떤 지표를 사용할지는 서비스 목적에 따라 달라진다”
예시:
의료 QA 서비스 → Recall 중요 (놓치면 안 되는 정보)
뉴스 요약 서비스 → ROUGE, BLEU로 내용 보존 여부 확인
고객 피드백 감성 분석 → F1 Score로 균형 평가
스팸 필터링 → Precision 중요 (정상 메시지를 차단하지 않도록)

---

## 3. 📘 자연어처리 Pipeline 이해하기

### 예시 Task: 낚시성 기사 분류 (6개 카테고리)
1. 환경설정 & 데이터 로딩
   ↓
2. 데이터 전처리 및 토크나이징
   ↓
3. 모델 및 토크나이저 로딩
   ↓
4. TrainingArguments 설정 & Trainer 학습
   ↓
5. 모델 평가 및 추론

### 1️⃣ **환경설정**

**목표**: 필요한 라이브러리 설치 + 데이터 불러오기

- **라이브러리**: `transformers`, `datasets`, `sklearn`, `torch`, `pandas` 등
- **데이터**: `train.csv`, `test.csv` (텍스트 + 카테고리 라벨)
- **PyTorch DataLoader 장점**:
    - 배치 학습(Batch Training)
    - 데이터 섞기(Shuffle)
    - 멀티 프로세싱 지원
    - 다른 PyTorch 구성요소들과 높은 호환성

---

### 2️⃣ **데이터셋 구축 + 토크나이징(Tokenizing)**

**목표**: 텍스트 데이터를 모델이 이해할 수 있도록 변환

- **Train/Valid 나누기**: 7.5:2.5로 나눠준 (split) —> 그러나, 보통 8:2 혹은 9:1로 분할
- **토크나이저 불러오기**:
    
    예: `BertTokenizer.from_pretrained('bert-base-uncased')`
    
- **주의**: 모델과 토크나이저는 **같은 checkpoint**여야 함
    
    예: `bert-base-uncased` 모델 ↔ 동일한 `bert-base-uncased` 토크나이저
    
- **출력 형태**: input_ids, attention_mask, label

---

### 3️⃣ **모델 및 토크나이저 로딩**

**목표**: 사전 학습된(pre-trained) 모델 기반 분류기 설정

---
### 4️⃣ **모델 학습: Trainer 사용**

**목표**: 학습을 자동화하고 최적화

- **TrainingArguments 설정**:
    
    로그 저장, 배치 사이즈, 에포크 수, 평가 전략 등 설정
    
- **Trainer 사용 이유**:
    - 학습 루프 간단화
    - 자동 평가, 로깅, 스케줄링, 조기 종료 등 지원
    - `compute_metrics`로 F1/Accuracy/Precision 등 커스터마이징 가능

---
### 5️⃣ **추론(Inference) 및 평가(Evaluation)**

**목표**: 테스트 데이터에 대해 분류 결과 예측하고 평가 지표 확인

- **모델 체크포인트 불러오기**:
    
    ```python
    python
    CopyEdit
    model = AutoModelForSequenceClassification.from_pretrained("results/checkpoint-best")
    ```
    
- **예측 수행**:
    
    ```python
    python
    CopyEdit
    predictions = trainer.predict(test_dataset)
    ```
    
- **평가 지표 예시**: Accuracy, Precision, Recall, F1 Score
- **활용 라이브러리**: `sklearn.metrics`

---


