---
layout: single
title: "ğŸŒ± BERT ì´ì „ì˜ ìì—°ì–´ì²˜ë¦¬ & NLP íŒŒì´í”„ë¼ì¸"
---

# Kernel Academy AI Bootcamp (2025.07.25)

ì´ë²ˆ í¬ìŠ¤íŠ¸ëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ íë¦„ì„ ì´í•´í•˜ê³ , BERT ì´ì „ì˜ ì£¼ìš” ëª¨ë¸ë“¤ê³¼ í•µì‹¬ ê°œë…ë“¤ì„ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤. ë˜í•œ, Hugging Face ê¸°ë°˜ì˜ NLP ë¶„ë¥˜ í”„ë¡œì íŠ¸ (ë‚šì‹œì„± ê¸°ì‚¬ ë¶„ë¥˜)ë¥¼ ì‹¤ìŠµí•˜ë©° ì „ì²´ Pipelineì„ êµ¬í˜„í•´ë³´ì•˜ìŠµë‹ˆë‹¤.

---

## ğŸ“Œ ëª©ì°¨

1. BERT ì´ì „ì˜ ì£¼ìš” NLP ëª¨ë¸ íë¦„
2. ìì—°ì–´ì²˜ë¦¬ Task ì´í•´ ë° Hugging Face Pipeline
3. NLP ëª¨ë¸ í•™ìŠµ ë° ì¶”ë¡  ì‹¤ìŠµ (ë‚šì‹œì„± ê¸°ì‚¬ ë¶„ë¥˜)
4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ìš”ì•½

---

## 1. BERT ì´ì „ì˜ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ íë¦„

### ğŸ” Seq2Seq (Sequence-to-Sequence)

- ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ê³ ì •ëœ ë²¡í„°ë¡œ ì¸ì½”ë”©í•œ í›„ ìƒˆë¡œìš´ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±  
- ì‘ìš© ë¶„ì•¼: **ê¸°ê³„ ë²ˆì—­**, **ì§ˆë¬¸ ìƒì„±**, **ì±—ë´‡**
- í•œê³„: ê¸´ ë¬¸ì¥ì¼ìˆ˜ë¡ ì •ë³´ ì†ì‹¤ â†’ **ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ**

### ğŸ”„ RNNê³¼ ê°œì„ í˜• êµ¬ì¡° (LSTM, GRU)

- ì‹œê°„ ìˆœì„œë¥¼ ë”°ë¼ ì •ë³´ë¥¼ ì „ë‹¬
- **LSTM**: ê²Œì´íŠ¸ êµ¬ì¡°ë¡œ ì¥ê¸° ì˜ì¡´ì„± ì™„í™”  
- **GRU**: LSTMë³´ë‹¤ ê°„ë‹¨í•˜ì§€ë§Œ ìœ ì‚¬í•œ ì„±ëŠ¥

### ğŸ¯ Attention Mechanism

- Encoderì˜ ë§ˆì§€ë§‰ ë²¡í„° ì˜ì¡´ ë¬¸ì œ í•´ê²°
- ë””ì½”ë”ê°€ ì…ë ¥ ì‹œí€€ìŠ¤ ì „ì²´ë¥¼ ì°¸ì¡° â†’ **ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì •ë³´ ì„ íƒ**
- ì¥ì : ë¬¸ë§¥ì— ë§ëŠ” ìœ ì—°í•œ ìƒì„± ê°€ëŠ¥

### âš¡ Transformer (2017)

- "Attention is All You Need"
- **ì™„ì „í•œ Attention ê¸°ë°˜ ëª¨ë¸**
- ë³‘ë ¬ ì—°ì‚° ê°€ëŠ¥ â†’ ëŒ€ê·œëª¨ í•™ìŠµì— ì í•©  
- í•µì‹¬ êµ¬ì„±: Self-Attention, Multi-Head Attention, Positional Encoding, FFN, Residual Connection
- Encoder-Decoder êµ¬ì¡°ëŠ” ìœ ì§€í•˜ì§€ë§Œ, ë‚´ë¶€ì ìœ¼ë¡œ RNN ì—†ì´ Attentionë§Œ ì‚¬ìš©

---

## 2. ğŸ“˜ ìì—°ì–´ì²˜ë¦¬ Task ì´í•´í•˜ê¸°

### ğŸ› Hugging Faceì™€ pipeline ëª¨ë“ˆ

```python
# ê°„ë‹¨í•œ ê°ì„± ë¶„ì„ ì˜ˆì‹œ
from transformers import pipeline
classifier = pipeline("sentiment-analysis")
print(classifier("I love this movie!"))
# ì¶œë ¥: [{'label': 'POSITIVE', 'score': 0.999...}]

**pipelineì€ ëª¨ë¸ ë¡œë”©, í† í¬ë‚˜ì´ì§•, ì¶”ë¡ , í›„ì²˜ë¦¬ë¥¼ ìë™í™”í•˜ì—¬ ê°„í¸í•œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•´ì¤Œ

| Task                               | ì„¤ëª…             |
| ---------------------------------- | -------------- |
| **ê¸°ê³„ ë²ˆì—­ (Translation)**            | ì–¸ì–´ A â†’ ì–¸ì–´ B    |
| **ì§ˆë¬¸ ì‘ë‹µ (QA)**                     | ì§ˆë¬¸ì— ëŒ€í•œ ì •ë‹µ ì¶”ì¶œ   |
| **ì •ë³´ ì¶”ì¶œ (Information Extraction)** | ë¬¸ì¥ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ    |
| **ê°ì„± ë¶„ë¥˜ (Sentiment Analysis)**     | í…ìŠ¤íŠ¸ì˜ ê°ì • íŒŒì•…     |
| **ìš”ì•½ (Summarization)**             | ê¸´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš© ì••ì¶• |

| ì§€í‘œ            | ì„¤ëª…                         |
| ------------- | -------------------------- |
| **Precision** | ì •ë‹µ íŒì • ì¤‘ ì‹¤ì œ ì •ë‹µ ë¹„ìœ¨           |
| **Recall**    | ì‹¤ì œ ì •ë‹µ ì¤‘ ë§ì¶˜ ë¹„ìœ¨              |
| **F1 Score**  | Precision + Recall ì¡°í™” í‰ê·    |
| **BLEU**      | ìƒì„± í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ì¸¡ì • (n-gram ê¸°ë°˜) |

â€œì–´ë–¤ ì§€í‘œë¥¼ ì‚¬ìš©í• ì§€ëŠ” ì„œë¹„ìŠ¤ ëª©ì ì— ë”°ë¼ ë‹¬ë¼ì§„ë‹¤â€
ì˜ˆì‹œ:
ì˜ë£Œ QA ì„œë¹„ìŠ¤ â†’ Recall ì¤‘ìš” (ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ì •ë³´)
ë‰´ìŠ¤ ìš”ì•½ ì„œë¹„ìŠ¤ â†’ ROUGE, BLEUë¡œ ë‚´ìš© ë³´ì¡´ ì—¬ë¶€ í™•ì¸
ê³ ê° í”¼ë“œë°± ê°ì„± ë¶„ì„ â†’ F1 Scoreë¡œ ê· í˜• í‰ê°€
ìŠ¤íŒ¸ í•„í„°ë§ â†’ Precision ì¤‘ìš” (ì •ìƒ ë©”ì‹œì§€ë¥¼ ì°¨ë‹¨í•˜ì§€ ì•Šë„ë¡)

---

## 3. ğŸ“˜ ìì—°ì–´ì²˜ë¦¬ Pipeline ì´í•´í•˜ê¸°

### ì˜ˆì‹œ Task: ë‚šì‹œì„± ê¸°ì‚¬ ë¶„ë¥˜ (6ê°œ ì¹´í…Œê³ ë¦¬)
1. í™˜ê²½ì„¤ì • & ë°ì´í„° ë¡œë”©
   â†“
2. ë°ì´í„° ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•
   â†“
3. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©
   â†“
4. TrainingArguments ì„¤ì • & Trainer í•™ìŠµ
   â†“
5. ëª¨ë¸ í‰ê°€ ë° ì¶”ë¡ 

### 1ï¸âƒ£ **í™˜ê²½ì„¤ì •**

**ëª©í‘œ**: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ + ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: `transformers`, `datasets`, `sklearn`, `torch`, `pandas` ë“±
- **ë°ì´í„°**: `train.csv`, `test.csv` (í…ìŠ¤íŠ¸ + ì¹´í…Œê³ ë¦¬ ë¼ë²¨)
- **PyTorch DataLoader ì¥ì **:
    - ë°°ì¹˜ í•™ìŠµ(Batch Training)
    - ë°ì´í„° ì„ê¸°(Shuffle)
    - ë©€í‹° í”„ë¡œì„¸ì‹± ì§€ì›
    - ë‹¤ë¥¸ PyTorch êµ¬ì„±ìš”ì†Œë“¤ê³¼ ë†’ì€ í˜¸í™˜ì„±

---

### 2ï¸âƒ£ **ë°ì´í„°ì…‹ êµ¬ì¶• + í† í¬ë‚˜ì´ì§•(Tokenizing)**

**ëª©í‘œ**: í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜

- **Train/Valid ë‚˜ëˆ„ê¸°**: 7.5:2.5ë¡œ ë‚˜ëˆ ì¤€ (split) â€”> ê·¸ëŸ¬ë‚˜, ë³´í†µ 8:2 í˜¹ì€ 9:1ë¡œ ë¶„í• 
- **í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°**:
    
    ì˜ˆ: `BertTokenizer.from_pretrained('bert-base-uncased')`
    
- **ì£¼ì˜**: ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ëŠ” **ê°™ì€ checkpoint**ì—¬ì•¼ í•¨
    
    ì˜ˆ: `bert-base-uncased` ëª¨ë¸ â†” ë™ì¼í•œ `bert-base-uncased` í† í¬ë‚˜ì´ì €
    
- **ì¶œë ¥ í˜•íƒœ**: input_ids, attention_mask, label

---

### 3ï¸âƒ£ **ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë”©**

**ëª©í‘œ**: ì‚¬ì „ í•™ìŠµëœ(pre-trained) ëª¨ë¸ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì„¤ì •

---
### 4ï¸âƒ£ **ëª¨ë¸ í•™ìŠµ: Trainer ì‚¬ìš©**

**ëª©í‘œ**: í•™ìŠµì„ ìë™í™”í•˜ê³  ìµœì í™”

- **TrainingArguments ì„¤ì •**:
    
    ë¡œê·¸ ì €ì¥, ë°°ì¹˜ ì‚¬ì´ì¦ˆ, ì—í¬í¬ ìˆ˜, í‰ê°€ ì „ëµ ë“± ì„¤ì •
    
- **Trainer ì‚¬ìš© ì´ìœ **:
    - í•™ìŠµ ë£¨í”„ ê°„ë‹¨í™”
    - ìë™ í‰ê°€, ë¡œê¹…, ìŠ¤ì¼€ì¤„ë§, ì¡°ê¸° ì¢…ë£Œ ë“± ì§€ì›
    - `compute_metrics`ë¡œ F1/Accuracy/Precision ë“± ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥

---
### 5ï¸âƒ£ **ì¶”ë¡ (Inference) ë° í‰ê°€(Evaluation)**

**ëª©í‘œ**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ë¶„ë¥˜ ê²°ê³¼ ì˜ˆì¸¡í•˜ê³  í‰ê°€ ì§€í‘œ í™•ì¸

- **ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°**:
    
    ```python
    python
    CopyEdit
    model = AutoModelForSequenceClassification.from_pretrained("results/checkpoint-best")
    ```
    
- **ì˜ˆì¸¡ ìˆ˜í–‰**:
    
    ```python
    python
    CopyEdit
    predictions = trainer.predict(test_dataset)
    ```
    
- **í‰ê°€ ì§€í‘œ ì˜ˆì‹œ**: Accuracy, Precision, Recall, F1 Score
- **í™œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬**: `sklearn.metrics`

---


