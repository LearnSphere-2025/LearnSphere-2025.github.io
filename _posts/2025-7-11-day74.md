---

layout: single
title: "Document Classification CV CompetitionğŸŒ±"
---------------------------------------------------------------------------------------------------

# Kernel Academy AI Bootcamp (July,11 2025)

It was an intense and rewarding two-week journey.
Through the curriculum of the AI Bootcamp, I participated in a **document image classification competition** using computer vision (CV) models, gaining experience from foundational concepts to hands-on applications.

---

## ğŸ§  Learning CV Models: From CNNs to Transformers

I started by understanding the structure of **CNNs (Convolutional Neural Networks)**.
However, for the competition, I had to explore stronger backbones.

* **CNN-based backbones**: Experiments with models like EfficientNet, ResNet
* **Transformer-based models**: Swin Transformer, BEiT, and other modern architectures
* **CV models**: Utilized various pretrained models using the `timm` library

Among these, I found **ConvNeXt** to be the most effective, and used it as my primary model.

---

## ğŸ§ª Experiments & Strategies for the Competition

To achieve the best results in a limited time, I applied a variety of techniques.

### ğŸ§© Offline & Online Augmentation

* **Offline Augmentation**: Used Albumentations, torchvision for dataset expansion
* **Online Augmentation**: Real-time strategies like mixup and cutmix to enhance generalization

### ğŸ² Ensuring Reproducibility and Stability

* Set `seed_everything` and `deterministic=True` to guarantee reproducibility
* Aimed to reproduce consistent results across various hardware environments

---

## ğŸ§¬ Model Training & Ensemble Techniques

### â™»ï¸ Cross Validation & Soft Ensemble

* **K-Fold cross-validation** for building robust models
* **Soft Ensemble**: Averaging predictions from multiple models to boost performance

### ğŸ§ª Test Time Augmentation (TTA)

* Applied different augmentations during inference and averaged the outputs
* Significantly improved generalization

At the end, I experimented with a **Stage-2 process** for post-processing.
Although I ran out of time for full fine-tuning, I believe **partial fine-tuning** would have further improved performance.

---

## ğŸ“ Reflections and Competition Results

This project went far beyond basic model training.
It allowed me to experience the full ML lifecycle, including training, validation, and reproducibility.
Since I lacked experience writing code from scratch, I utilized **ChatGPT to help build my training pipelines and experiments**.
As a result, I achieved a **high leaderboard score of 0.9595**.
By trying out various techniques, I was able to experience **practical, near-industry-level experimentation** and grow rapidly in a short period of time.

---

## ğŸ“š Key Takeaways

* Hands-on application of deep learning architectures for image classification
* Strategic combination of augmentation and regularization
* Reproducible and stable experiment management
* Generalization boost via soft ensembling and TTA
* Learned dataset handling and code optimization through real competition

---

#### ğŸ”– Hashtags

#íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤AIë¶€íŠ¸ìº í”„ #ì—…ìŠ¤í…Œì´ì§€íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ #UpstageAILab #êµ­ë¹„ì§€ì› #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì—…ìŠ¤í…Œì´ì§€ì—ì´ì•„ì´ë© #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì—…ìŠ¤í…Œì´ì§€ë¶€íŠ¸ìº í”„

