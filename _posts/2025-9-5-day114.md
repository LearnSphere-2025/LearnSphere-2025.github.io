---  
layout: single
title: "Data Centric AI✨"  
---

# Kernel Academy AI Bootcamp (September 5, 2025)

Today, I’ll summarize what I’ve learned about **Data Centric AI**. Data-Centric AI is an approach to building AI systems that emphasizes improving the quality and management of data rather than focusing solely on making models more complex

---

## 🪢 Data Lifecycle Stages

1. Data Collection
- Representativeness: Ensure the dataset reflects the real-world application domain.
- Class Balance: Collect enough samples for minority classes to avoid imbalance.
- Diversity: Capture various scenarios and conditions within each class.
- Quality Control: Minimize duplicates and irrelevant data.

2. Data Preprocessing
- Missing Values: Handle by removal, mean/median imputation, or model-based imputation.
- Outlier Detection: Use distribution-based, statistical (IQR, Z-score), or model-based methods.
- Format Conversion: One-hot encoding for categorical variables, scaling/normalization for numerical data.
- Domain-Specific Normalization: Text cleaning, image resizing/normalization, audio preprocessing, etc.

3. Data Labeling
- Guideline Documentation: Provide detailed instructions to maintain consistency among labelers.
- Pilot Labeling: Start with a small dataset to test and refine guidelines.
- Multiple Labeling: Assign important samples to multiple annotators independently.
- Label Quality Evaluation: 2 annotators → Cohen’s Kappa &  3 or more annotators → Fleiss’ Kappa or F1 score
- Quality Control: Use gold standard samples, monitor annotator disagreement.

4. Data Cleansing
- Duplicate Removal: Eliminate identical or near-duplicate samples.
- Noise Removal/Correction: Fix incorrect labels or corrupted files.
- Sample Balancing: Apply oversampling, undersampling, or data augmentation.
- Label Refinement: Resolve disagreements via majority voting or expert review.

5. Data Split (Train / Validation / Test)
- Train Set: Model training (typically 60–80%).
- Validation Set: Hyperparameter tuning and model selection (10–20%).
- Test Set: Final performance evaluation (10–20%).
- Best Practices: Prevent duplicates from being split across sets. Use stratified splitting to preserve class distribution.

6. Data Release
- Data Versioning: Use DVC, Git LFS, or Weights & Biases Artifacts.
- Documentation: Create dataset cards (Data Sheets, Model Cards): Include collection methods, labeling guidelines, limitations, and ethical considerations.
- Security & Privacy: Apply anonymization and remove sensitive information.
- Distribution: Internal repositories, cloud platforms, or public platforms (Kaggle, Hugging Face Datasets, etc.).

---

#### 🔖 Hashtags  
`#Data #Centric #AI #Labeling #bootcamp #AIbootcamp #AIframework`  
'#패스트캠퍼스 #패스트캠퍼스AI부트캠프 #업스테이지패스트캠퍼스 #UpstageAILab #국비지원 #패스트캠퍼스업스테이지에이아이랩 #패스트캠퍼스업스테이지부트캠프'
