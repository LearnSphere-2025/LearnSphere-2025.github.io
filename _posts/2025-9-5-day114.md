---  
layout: single
title: "Data Centric AIâœ¨"  
---

# Kernel Academy AI Bootcamp (September 5, 2025)

Today, Iâ€™ll summarize what Iâ€™ve learned about **Data Centric AI**. Data-Centric AI is an approach to building AI systems that emphasizes improving the quality and management of data rather than focusing solely on making models more complex

---

## ğŸª¢ Data Lifecycle Stages

1. Data Collection
- Representativeness: Ensure the dataset reflects the real-world application domain.
- Class Balance: Collect enough samples for minority classes to avoid imbalance.
- Diversity: Capture various scenarios and conditions within each class.
- Quality Control: Minimize duplicates and irrelevant data.

2. Data Preprocessing
- Missing Values: Handle by removal, mean/median imputation, or model-based imputation.
- Outlier Detection: Use distribution-based, statistical (IQR, Z-score), or model-based methods.
- Format Conversion: One-hot encoding for categorical variables, scaling/normalization for numerical data.
- Domain-Specific Normalization: Text cleaning, image resizing/normalization, audio preprocessing, etc.

3. Data Labeling
- Guideline Documentation: Provide detailed instructions to maintain consistency among labelers.
- Pilot Labeling: Start with a small dataset to test and refine guidelines.
- Multiple Labeling: Assign important samples to multiple annotators independently.
- Label Quality Evaluation: 2 annotators â†’ Cohenâ€™s Kappa &  3 or more annotators â†’ Fleissâ€™ Kappa or F1 score
- Quality Control: Use gold standard samples, monitor annotator disagreement.

4. Data Cleansing
- Duplicate Removal: Eliminate identical or near-duplicate samples.
- Noise Removal/Correction: Fix incorrect labels or corrupted files.
- Sample Balancing: Apply oversampling, undersampling, or data augmentation.
- Label Refinement: Resolve disagreements via majority voting or expert review.

5. Data Split (Train / Validation / Test)
- Train Set: Model training (typically 60â€“80%).
- Validation Set: Hyperparameter tuning and model selection (10â€“20%).
- Test Set: Final performance evaluation (10â€“20%).
- Best Practices: Prevent duplicates from being split across sets. Use stratified splitting to preserve class distribution.

6. Data Release
- Data Versioning: Use DVC, Git LFS, or Weights & Biases Artifacts.
- Documentation: Create dataset cards (Data Sheets, Model Cards): Include collection methods, labeling guidelines, limitations, and ethical considerations.
- Security & Privacy: Apply anonymization and remove sensitive information.
- Distribution: Internal repositories, cloud platforms, or public platforms (Kaggle, Hugging Face Datasets, etc.).

---

#### ğŸ”– Hashtags  
`#Data #Centric #AI #Labeling #bootcamp #AIbootcamp #AIframework`  
'#íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤AIë¶€íŠ¸ìº í”„ #ì—…ìŠ¤í…Œì´ì§€íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ #UpstageAILab #êµ­ë¹„ì§€ì› #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì—…ìŠ¤í…Œì´ì§€ì—ì´ì•„ì´ë© #íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ì—…ìŠ¤í…Œì´ì§€ë¶€íŠ¸ìº í”„'
