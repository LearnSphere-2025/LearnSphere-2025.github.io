---
layout: single
title: "Kaggle training failure and lessons from the CommunityğŸ§ "
---

# Kernel Academy AI Bootcamp (October 7, 2025)

---

## ğŸ§¨ Training Failed and Resource Limitations

- After a full 10-hour training session, the model failed to save due to an unexpected error
- GPU usage limit reached, so further training wasn't possible
- This reminded me how crucial **planning experiments** and managing resources properly is

---

## ğŸ§­ What I Learned from Reading the Community Posts

Since I couldn't continue experimenting, I spent time reading through the **Kaggle competition community posts** in reverse order â€” about **20% of the total posts** so far.  
To my surprise, I found several key insights and **realized I had misunderstood important rules**.

### â— Misinterpreting the Competition Rules

> I misunderstood the "GPU usage within 10 hours" rule as a **training time constraint**, but it **actually applies only to inference time**.

This mistake led me to unnecessarily restrict my training time and, in hindsight, **hurt model performance**.

![community](/assets/images/kaggle-day5.jpg)

---

## ğŸ“¦ Learning from Experts: Efficient and Fast Training is Possible

While browsing community threads, I came across a post by a **Kaggle Master** who trained a **Qwen3-4b** model.

- Completed training in **under 2 hours**
- Inference was also very fast
- In contrast, my setup:  
  - Training: **10+ hours (1 epoch, 1 fold)**  
  - Inference: **Over 5 hours**

> Even though we used similar models, the performance and efficiency were completely different.  
> Itâ€™s clear that **thereâ€™s a structural issue in my code or training strategy**.

---

## ğŸ¯ Reflection and Next Steps

This was my **first Kaggle competition**, and I now realize how much I **missed out by not reading the rules and community threads early on**.  
If I had done so, I could have saved resources and possibly achieved better results.

For the remaining holiday, my plan is to:

- ğŸ“˜ Read more community discussions  
- ğŸ” Study code and strategies from experienced participants  
- âš™ï¸ Optimize inference time and refactor my code

Iâ€™m motivated to work even harder moving forward.

---

#### ğŸ”– Hashtags  
`#AIë¶€íŠ¸ìº í”„ #ì»¤ë„ì•„ì¹´ë°ë¯¸ #ì»¤ë„ì•„ì¹´ë°ë¯¸ë¶€íŠ¸ìº í”„ #ì»¤ë„ì•„ì¹´ë°ë¯¸AIë¶€íŠ¸ìº í”„ #Kaggle`
