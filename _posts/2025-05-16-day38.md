---
layout: single
title: "Apartment Price Prediction Competition Challenge ğŸ¡"
---

# Kernel Academy AI Bootcamp (May 2025)

After learning the fundamentals of machine learning in the bootcamp, I joined a real-world **apartment price prediction competition** to gain hands-on experience.  
In this post, Iâ€™ll share how I applied what I learned and reflect on the challenges and achievements from the competition.

---

## ğŸ“š Machine Learning Basics

At first, even the terminology in machine learning was unfamiliar. But over time, the concepts started to click.

- Understanding of **Supervised Learning** workflow
- Familiarity with various algorithms such as **Linear Regression**, **Decision Trees**, and **Ensemble Models**
- Strategies to avoid **overfitting** (e.g., Regularization, Cross-Validation)
- Use of evaluation metrics like **RMSE** and **MAE**

---

## ğŸ† Participation in Apartment Price Prediction Competition

Joining the competition gave me a chance to experience the full modeling pipeline.

### ğŸ“ Dataset Overview

- **Train Data (train.csv)**: Apartment features (location, size, floor, year built, etc.) with actual prices
- **Test Data (test.csv)**: Same structure, but without prices
- **Objective**: Predict the apartment prices in the test data

### ğŸ” Data Preprocessing (EDA)

- Handled **missing values**
- Detected and removed **outliers**
- Encoded categorical variables (Label Encoding / One-hot / Target Encoding)
- Applied feature scaling (StandardScaler, MinMaxScaler, etc.)

### ğŸ§  Modeling

Tried various regression algorithms:

- **Linear Regression**
- **Random Forest Regressor**
- **XGBoost Regressor**
- **LightGBM**

#### ğŸ“ˆ Final Model: Random Forest

**Random Forest** performed the best in terms of prediction accuracy and stability.

- Feature: An ensemble of decision trees that averages predictions to reduce overfitting
- Evaluation (RMSE): **14,147**
- Final Leaderboard Rank: **Our team placed 4th**

---

## ğŸ’¡ Retrospective

Key takeaways from this competition:

- Real-world data is messy â†’ preprocessing is crucial
- Understood the importance of **feature engineering**
- Experimenting with various algorithms helped deepen practical understanding
- **Time Series Validation** was more effective than k-fold for this dataset
- More features often led to better model performance

Above all, I learned how to approach problem-solving through a **data-driven mindset**â€”a major milestone in my learning journey.

---

## ğŸ“ Resources & Code

ğŸ”— [Competition Submission Code (GitHub)](https://github.com/yourusername/apt-price-prediction)  
ğŸ“„ [Data Source: KOSIS / Kaggle](https://kosis.kr)

---

#### ğŸ”– Hashtags  
`#ApartmentPricePrediction #MachineLearning #AIbootcamp #Kaggle #BootcampProject #RandomForest #Regression #DataScience #FastCampus #UpstageAILab`
